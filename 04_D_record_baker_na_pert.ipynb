{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbbbf7a",
   "metadata": {},
   "source": [
    "# Simulate neural recordings using variations of NA population fit to Baker et al data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53237cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import signal, stats\n",
    "from sklearn import linear_model\n",
    "import sys\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from aux import get_seg, load_npy\n",
    "from disp import set_font_size\n",
    "from my_stats import nanpearsonr\n",
    "\n",
    "from record_0_main import smlt_ma\n",
    "\n",
    "cc = np.concatenate\n",
    "\n",
    "FPS = 30.03  # sampling rate of behavioral data\n",
    "DT = 1/FPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e8892",
   "metadata": {},
   "source": [
    "Load behavioral data from Coen et al 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_behav = pd.read_csv('data/simple/c_song_f_behav.csv')\n",
    "df_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73020b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split big df into dfs for individual trials\n",
    "n_tr = np.max(df_behav.ID) + 1\n",
    "dfs_tr = [df_behav[df_behav.ID == i] for i in range(n_tr)]\n",
    "\n",
    "tr_lens = np.array([len(df_tr) for df_tr in dfs_tr])\n",
    "tr_lens_cum = cc([[0], np.cumsum(tr_lens)])\n",
    "\n",
    "n_t_total = np.sum(tr_lens)\n",
    "assert n_t_total == tr_lens_cum[-1]\n",
    "df_behav = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5320c60",
   "metadata": {},
   "source": [
    "# Baseline MA model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a105b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural response fits from Baker data\n",
    "ma_param = load_npy('data/simple/neur/baker_ma.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337352e4",
   "metadata": {},
   "source": [
    "# No selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5dbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'no_sel'\n",
    "SAVE_DIR = f'data/simple/mlv/ma_pert/baker_ma_{KEY}'\n",
    "SAVE_PFX = f'mlv_baker_ma_{KEY}'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "ma_param = load_npy('data/simple/neur/baker_ma.npy')\n",
    "mn_selectivity = np.mean(np.array([ma_param['X_S'], ma_param['X_P']]).T, axis=1)\n",
    "ma_param['X_S'] = mn_selectivity\n",
    "ma_param['X_P'] = mn_selectivity\n",
    "pd.DataFrame(data=ma_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc81d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    # simulate ppln response\n",
    "    rs = smlt_ma(i_s, i_p, ma_param, DT)\n",
    "        \n",
    "    df_tr_nrl[[f'R_{expt_id}' for expt_id in ma_param['EXPT_ID']]] = rs\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR, f'{SAVE_PFX}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f3677",
   "metadata": {},
   "source": [
    "# Pure selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'pure_sel'\n",
    "SAVE_DIR = f'data/simple/mlv/ma_pert/baker_ma_{KEY}'\n",
    "SAVE_PFX = f'mlv_baker_ma_{KEY}'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "ma_param = load_npy('data/simple/neur/baker_ma.npy')\n",
    "ms_selective = np.abs(ma_param['X_S']) > np.abs(ma_param['X_P'])\n",
    "mp_selective = np.abs(ma_param['X_P']) > np.abs(ma_param['X_S'])\n",
    "ma_param['X_S'][mp_selective] = 0\n",
    "ma_param['X_P'][ms_selective] = 0\n",
    "pd.DataFrame(data=ma_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afde690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    # simulate ppln response\n",
    "    rs = smlt_ma(i_s, i_p, ma_param, DT)\n",
    "        \n",
    "    df_tr_nrl[[f'R_{expt_id}' for expt_id in ma_param['EXPT_ID']]] = rs\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR, f'{SAVE_PFX}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae66e0",
   "metadata": {},
   "source": [
    "# Sine selectivity only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'sine_sel'\n",
    "SAVE_DIR = f'data/simple/mlv/ma_pert/baker_ma_{KEY}'\n",
    "SAVE_PFX = f'mlv_baker_ma_{KEY}'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "ma_param = load_npy('data/simple/neur/baker_ma.npy')\n",
    "ma_param['X_P'] = 0\n",
    "pd.DataFrame(data=ma_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd508579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    # simulate ppln response\n",
    "    rs = smlt_ma(i_s, i_p, ma_param, DT)\n",
    "        \n",
    "    df_tr_nrl[[f'R_{expt_id}' for expt_id in ma_param['EXPT_ID']]] = rs\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR, f'{SAVE_PFX}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056e535",
   "metadata": {},
   "source": [
    "# Pulse selectivity only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c5e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'pulse_sel'\n",
    "SAVE_DIR = f'data/simple/mlv/ma_pert/baker_ma_{KEY}'\n",
    "SAVE_PFX = f'mlv_baker_ma_{KEY}'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "ma_param = load_npy('data/simple/neur/baker_ma.npy')\n",
    "ma_param['X_S'] = 0\n",
    "pd.DataFrame(data=ma_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940334bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    # simulate ppln response\n",
    "    rs = smlt_ma(i_s, i_p, ma_param, DT)\n",
    "        \n",
    "    df_tr_nrl[[f'R_{expt_id}' for expt_id in ma_param['EXPT_ID']]] = rs\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR, f'{SAVE_PFX}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c264c4",
   "metadata": {},
   "source": [
    "# No adaptation\n",
    "\n",
    "All $\\tau_a$ set to $\\infty$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = 'no_adapt'\n",
    "SAVE_DIR = f'data/simple/mlv/ma_pert/baker_ma_{KEY}'\n",
    "SAVE_PFX = f'mlv_baker_ma_{KEY}'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "ma_param = load_npy('data/simple/neur/baker_ma.npy')\n",
    "ma_param['TAU_A'] = np.inf\n",
    "pd.DataFrame(data=ma_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0573650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    # simulate ppln response\n",
    "    rs = smlt_ma(i_s, i_p, ma_param, DT)\n",
    "        \n",
    "    df_tr_nrl[[f'R_{expt_id}' for expt_id in ma_param['EXPT_ID']]] = rs\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR, f'{SAVE_PFX}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a3838",
   "metadata": {},
   "source": [
    "# Bounded response and adaptation timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS_RTAU_RS_RTAU_AS = [\n",
    "    ('fast_r_fast_a', [.1, 2], [.1, 2]),\n",
    "    ('fast_r_med_a', [.1, 2], [2, 20]),\n",
    "    ('fast_r_slow_a', [.1, 2], [20, 120]),\n",
    "    ('med_r_fast_a', [2, 20], [.1, 2]),\n",
    "    ('med_r_med_a', [2, 20], [2, 20]),\n",
    "    ('med_r_slow_a', [2, 20], [20, 120]),\n",
    "    ('slow_r_fast_a', [20, 120], [.1, 2]),\n",
    "    ('slow_r_med_a', [20, 120], [2, 20]),\n",
    "    ('slow_r_slow_a', [20, 120], [20, 120]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, rtau_r, rtau_a in KEYS_RTAU_RS_RTAU_AS:\n",
    "    print(key)\n",
    "    SAVE_DIR = f'data/simple/mlv/ma_pert/baker_ma_{key}'\n",
    "    SAVE_PFX = f'mlv_baker_ma_{key}'\n",
    "\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)\n",
    "        \n",
    "    ma_param = load_npy('data/simple/neur/baker_ma.npy')\n",
    "    ma_param['TAU_R'] = np.random.uniform(*rtau_r, len(ma_param['TAU_R']))\n",
    "    ma_param['TAU_A'] = np.random.uniform(*rtau_a, len(ma_param['TAU_A']))\n",
    "    \n",
    "    for ctr, df_tr in enumerate(dfs_tr):\n",
    "        df_tr_nrl = df_tr.copy()\n",
    "        sys.stdout.write('.')\n",
    "\n",
    "        i_s = np.array(df_tr['S']).astype(float)\n",
    "        i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "\n",
    "        # simulate ppln response\n",
    "        rs = smlt_ma(i_s, i_p, ma_param, DT)\n",
    "\n",
    "        df_tr_nrl[[f'R_{expt_id}' for expt_id in ma_param['EXPT_ID']]] = rs\n",
    "\n",
    "        np.save(os.path.join(SAVE_DIR, f'{SAVE_PFX}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl}]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
