{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expanded-consistency",
   "metadata": {},
   "source": [
    "Create surrogate neural population responses during natural behavior trials using variations on dynamical adapting neural models of Baker et al data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import signal, stats\n",
    "from sklearn import linear_model\n",
    "import sys\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from aux import get_seg\n",
    "from disp import set_font_size\n",
    "from my_stats import nanpearsonr\n",
    "\n",
    "cc = np.concatenate\n",
    "\n",
    "FPS = 30.03  # sampling rate of behavioral data\n",
    "DT = 1/FPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-opportunity",
   "metadata": {},
   "source": [
    "Load behavioral data from Coen et al 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_behav = pd.read_csv('data/simple/c_song_f_behav.csv')\n",
    "df_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split big df into dfs for individual trials\n",
    "n_tr = np.max(df_behav.ID) + 1\n",
    "dfs_tr = [df_behav[df_behav.ID == i] for i in range(n_tr)]\n",
    "\n",
    "tr_lens = np.array([len(df_tr) for df_tr in dfs_tr])\n",
    "tr_lens_cum = cc([[0], np.cumsum(tr_lens)])\n",
    "\n",
    "n_t_total = np.sum(tr_lens)\n",
    "assert n_t_total == tr_lens_cum[-1]\n",
    "df_behav = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-oriental",
   "metadata": {},
   "source": [
    "# Simulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define smln & obj function\n",
    "def smlt(i_s, i_p, tau_r, tau_a, x_s, x_p):\n",
    "    \"\"\"Simulate response to song inputs.\"\"\"\n",
    "    t = np.arange(len(i_s))*DT\n",
    "    r = np.nan*np.zeros(len(t))\n",
    "    \n",
    "    r[0] = 0\n",
    "    a_s, a_p = 0, 0\n",
    "    \n",
    "    for ct, t_ in enumerate(t[1:], 1):\n",
    "        a_s += ((DT/tau_a) * (-a_s + x_s*i_s[ct]))\n",
    "        a_p += ((DT/tau_a) * (-a_p + x_p*i_p[ct]))\n",
    "        r[ct] = r[ct-1] + (DT/tau_r) * (-r[ct-1] + (x_s - a_s)*i_s[ct] + (x_p - a_p)*i_p[ct])\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-variety",
   "metadata": {},
   "source": [
    "# Baseline dynamical model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural response fits from Baker data\n",
    "df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "df_dyn_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-attitude",
   "metadata": {},
   "source": [
    "# Dynamical model without adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_DYN = 'data/simple/mlv_c/perturbed_ppln/c_baker_dyn_nonadapt'\n",
    "SAVE_PFX_DYN = 'mlv_c_baker_dyn_nonadapt'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_DYN):\n",
    "    os.makedirs(SAVE_DIR_DYN)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "df_dyn_param['TAU_A'] = np.inf\n",
    "df_dyn_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_dyn_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_dyn_param['TAU_R'])\n",
    "tau_as = np.array(df_dyn_param['TAU_A'])\n",
    "x_ss = np.array(df_dyn_param['X_S'])\n",
    "x_ps = np.array(df_dyn_param['X_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_dyn = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    # loop over neurons\n",
    "    for expt_id, tau_r, tau_a, x_s, x_p in zip(expt_ids, tau_rs, tau_as, x_ss, x_ps):\n",
    "        # compute surrogate neural response\n",
    "        i_s = np.array(df_tr['S']).astype(float)\n",
    "        i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "        \n",
    "        r = smlt(i_s, i_p, tau_r, tau_a, x_s, x_p)\n",
    "        \n",
    "        df_tr_nrl_dyn[f'R_{expt_id}'] = r\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_DYN, f'{SAVE_PFX_DYN}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl_dyn}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-norman",
   "metadata": {},
   "source": [
    "# Dynamical model with homogeneous timescales\n",
    "(Response and adaptation timescales are set to median values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_DYN = 'data/simple/mlv_c/perturbed_ppln/c_baker_dyn_taufixed'\n",
    "SAVE_PFX_DYN = 'mlv_c_baker_dyn_taufixed'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_DYN):\n",
    "    os.makedirs(SAVE_DIR_DYN)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "tau_r_med = np.median(df_dyn_param['TAU_R'])\n",
    "tau_a_med = np.median(df_dyn_param['TAU_A'])\n",
    "print('Median TAU_R:', tau_r_med)\n",
    "print('Median TAU_A:', tau_a_med)\n",
    "df_dyn_param['TAU_R'] = tau_r_med\n",
    "df_dyn_param['TAU_A'] = tau_a_med\n",
    "df_dyn_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_dyn_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_dyn_param['TAU_R'])\n",
    "tau_as = np.array(df_dyn_param['TAU_A'])\n",
    "x_ss = np.array(df_dyn_param['X_S'])\n",
    "x_ps = np.array(df_dyn_param['X_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_dyn = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    # loop over neurons\n",
    "    for expt_id, tau_r, tau_a, x_s, x_p in zip(expt_ids, tau_rs, tau_as, x_ss, x_ps):\n",
    "        # compute surrogate neural response\n",
    "        i_s = np.array(df_tr['S']).astype(float)\n",
    "        i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "        \n",
    "        r = smlt(i_s, i_p, tau_r, tau_a, x_s, x_p)\n",
    "        \n",
    "        df_tr_nrl_dyn[f'R_{expt_id}'] = r\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_DYN, f'{SAVE_PFX_DYN}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl_dyn}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-material",
   "metadata": {},
   "source": [
    "# Loop over value of homogeneous timescales\n",
    "\n",
    "No adaptation -- homogeneous response timescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAU_RS = [.1, .5, 1, 2, 3, 5, 7, 10, 15, 20, 30]\n",
    "for tau_r in TAU_RS:\n",
    "    print(f'Fixed TAU_R = {tau_r} s')\n",
    "    SAVE_DIR_DYN = f'data/simple/mlv_c/perturbed_ppln/c_baker_dyn_taufixed_{tau_r}'\n",
    "    SAVE_PFX_DYN = f'mlv_c_baker_dyn_taufixed_{tau_r}'\n",
    "\n",
    "    if not os.path.exists(SAVE_DIR_DYN):\n",
    "        os.makedirs(SAVE_DIR_DYN)\n",
    "\n",
    "    # neural response fits from Baker data\n",
    "    df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "    df_dyn_param['TAU_R'] = tau_r\n",
    "    df_dyn_param['TAU_A'] = np.inf\n",
    "\n",
    "    expt_ids = df_dyn_param['EXPT_ID']\n",
    "\n",
    "    # get parameters\n",
    "    tau_rs = np.array(df_dyn_param['TAU_R'])\n",
    "    tau_as = np.array(df_dyn_param['TAU_A'])\n",
    "    x_ss = np.array(df_dyn_param['X_S'])\n",
    "    x_ps = np.array(df_dyn_param['X_P'])\n",
    "\n",
    "    # compute surrogate neural responses for each trial\n",
    "    for ctr, df_tr in enumerate(dfs_tr):\n",
    "        df_tr_nrl_dyn = df_tr.copy()\n",
    "        sys.stdout.write('.')\n",
    "        # loop over neurons\n",
    "        for expt_id, tau_r, tau_a, x_s, x_p in zip(expt_ids, tau_rs, tau_as, x_ss, x_ps):\n",
    "            # compute surrogate neural response\n",
    "            i_s = np.array(df_tr['S']).astype(float)\n",
    "            i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "\n",
    "            r = smlt(i_s, i_p, tau_r, tau_a, x_s, x_p)\n",
    "\n",
    "            df_tr_nrl_dyn[f'R_{expt_id}'] = r\n",
    "\n",
    "        np.save(os.path.join(SAVE_DIR_DYN, f'{SAVE_PFX_DYN}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl_dyn}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-overview",
   "metadata": {},
   "source": [
    "# Dynamical model with non-selective neurons\n",
    "(All responses respond equally to sine and pulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_DYN = 'data/simple/mlv_c/perturbed_ppln/c_baker_dyn_nonselect'\n",
    "SAVE_PFX_DYN = 'mlv_c_baker_dyn_nonselect'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_DYN):\n",
    "    os.makedirs(SAVE_DIR_DYN)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "x_sp_mean = np.mean(np.array(df_dyn_param[['X_S', 'X_P']]), axis=1)\n",
    "df_dyn_param['X_S'] = x_sp_mean\n",
    "df_dyn_param['X_P'] = x_sp_mean\n",
    "df_dyn_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_dyn_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_dyn_param['TAU_R'])\n",
    "tau_as = np.array(df_dyn_param['TAU_A'])\n",
    "x_ss = np.array(df_dyn_param['X_S'])\n",
    "x_ps = np.array(df_dyn_param['X_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_dyn = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    # loop over neurons\n",
    "    for expt_id, tau_r, tau_a, x_s, x_p in zip(expt_ids, tau_rs, tau_as, x_ss, x_ps):\n",
    "        # compute surrogate neural response\n",
    "        i_s = np.array(df_tr['S']).astype(float)\n",
    "        i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "        \n",
    "        r = smlt(i_s, i_p, tau_r, tau_a, x_s, x_p)\n",
    "        \n",
    "        df_tr_nrl_dyn[f'R_{expt_id}'] = r\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_DYN, f'{SAVE_PFX_DYN}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl_dyn}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-narrow",
   "metadata": {},
   "source": [
    "# Dynamical model with purely selective neurons\n",
    "(Every neuron responds only to its preferred song mode.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_DYN = 'data/simple/mlv_c/perturbed_ppln/c_baker_dyn_pureselect'\n",
    "SAVE_PFX_DYN = 'mlv_c_baker_dyn_pureselect'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_DYN):\n",
    "    os.makedirs(SAVE_DIR_DYN)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "x_s_alt = []\n",
    "x_p_alt = []\n",
    "\n",
    "for irow, row in df_dyn_param.iterrows():\n",
    "    if np.abs(row['X_S']) > np.abs(row['X_P']):\n",
    "        x_s_alt.append(row['X_S'])\n",
    "        x_p_alt.append(0)\n",
    "    else:\n",
    "        x_s_alt.append(0)\n",
    "        x_p_alt.append(row['X_P'])\n",
    "        \n",
    "df_dyn_param['X_S'] = x_s_alt\n",
    "df_dyn_param['X_P'] = x_p_alt\n",
    "df_dyn_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_dyn_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_dyn_param['TAU_R'])\n",
    "tau_as = np.array(df_dyn_param['TAU_A'])\n",
    "x_ss = np.array(df_dyn_param['X_S'])\n",
    "x_ps = np.array(df_dyn_param['X_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_dyn = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    # loop over neurons\n",
    "    for expt_id, tau_r, tau_a, x_s, x_p in zip(expt_ids, tau_rs, tau_as, x_ss, x_ps):\n",
    "        # compute surrogate neural response\n",
    "        i_s = np.array(df_tr['S']).astype(float)\n",
    "        i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "        \n",
    "        r = smlt(i_s, i_p, tau_r, tau_a, x_s, x_p)\n",
    "        \n",
    "        df_tr_nrl_dyn[f'R_{expt_id}'] = r\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_DYN, f'{SAVE_PFX_DYN}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl_dyn}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-batman",
   "metadata": {},
   "source": [
    "# Dynamical model with shuffled parameters\n",
    "(Marginal param distributions across neurons are kept but correlations are broken.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_DYN = 'data/simple/mlv_c/perturbed_ppln/c_baker_dyn_paramshuffle'\n",
    "SAVE_PFX_DYN = 'mlv_c_baker_dyn_paramshuffle'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_DYN):\n",
    "    os.makedirs(SAVE_DIR_DYN)\n",
    "\n",
    "np.random.seed(0)\n",
    "# neural response fits from Baker data\n",
    "df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "df_dyn_param['TAU_R'] = np.array(df_dyn_param['TAU_R'])[np.random.permutation(len(df_dyn_param))]\n",
    "df_dyn_param['TAU_A'] = np.array(df_dyn_param['TAU_A'])[np.random.permutation(len(df_dyn_param))]\n",
    "df_dyn_param['X_S'] = np.array(df_dyn_param['X_S'])[np.random.permutation(len(df_dyn_param))]\n",
    "df_dyn_param['X_P'] = np.array(df_dyn_param['X_P'])[np.random.permutation(len(df_dyn_param))]\n",
    "df_dyn_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_dyn_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_dyn_param['TAU_R'])\n",
    "tau_as = np.array(df_dyn_param['TAU_A'])\n",
    "x_ss = np.array(df_dyn_param['X_S'])\n",
    "x_ps = np.array(df_dyn_param['X_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_dyn = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    # loop over neurons\n",
    "    for expt_id, tau_r, tau_a, x_s, x_p in zip(expt_ids, tau_rs, tau_as, x_ss, x_ps):\n",
    "        # compute surrogate neural response\n",
    "        i_s = np.array(df_tr['S']).astype(float)\n",
    "        i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "        \n",
    "        r = smlt(i_s, i_p, tau_r, tau_a, x_s, x_p)\n",
    "        \n",
    "        df_tr_nrl_dyn[f'R_{expt_id}'] = r\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_DYN, f'{SAVE_PFX_DYN}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl_dyn}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-insurance",
   "metadata": {},
   "source": [
    "# Dynamical model with shuffled parameters downsampled\n",
    "(Marginal param distributions across neurons are kept but correlations are broken.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "NR = [150, 100, 50, 25, 10]\n",
    "\n",
    "for nr in NR:\n",
    "    print('NR =', nr)\n",
    "    SAVE_DIR_DYN = f'data/simple/mlv_c/perturbed_ppln/c_baker_dyn_paramshuffle_nr_{nr}'\n",
    "    SAVE_PFX_DYN = f'mlv_c_baker_dyn_paramshuffle_nr_{nr}'\n",
    "\n",
    "    if not os.path.exists(SAVE_DIR_DYN):\n",
    "        os.makedirs(SAVE_DIR_DYN)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    # neural response fits from Baker data\n",
    "    df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "    df_dyn_param['TAU_R'] = np.array(df_dyn_param['TAU_R'])[np.random.permutation(len(df_dyn_param))]\n",
    "    df_dyn_param['TAU_A'] = np.array(df_dyn_param['TAU_A'])[np.random.permutation(len(df_dyn_param))]\n",
    "    df_dyn_param['X_S'] = np.array(df_dyn_param['X_S'])[np.random.permutation(len(df_dyn_param))]\n",
    "    df_dyn_param['X_P'] = np.array(df_dyn_param['X_P'])[np.random.permutation(len(df_dyn_param))]\n",
    "\n",
    "    expt_ids = np.arange(nr, dtype=int)\n",
    "\n",
    "    # get parameters\n",
    "    tau_rs = np.array(df_dyn_param['TAU_R'])[:nr]\n",
    "    tau_as = np.array(df_dyn_param['TAU_A'])[:nr]\n",
    "    x_ss = np.array(df_dyn_param['X_S'])[:nr]\n",
    "    x_ps = np.array(df_dyn_param['X_P'])[:nr]\n",
    "\n",
    "    # compute surrogate neural responses for each trial\n",
    "    for ctr, df_tr in enumerate(dfs_tr):\n",
    "        df_tr_nrl_dyn = df_tr.copy()\n",
    "        sys.stdout.write('.')\n",
    "        # loop over neurons\n",
    "        for expt_id, tau_r, tau_a, x_s, x_p in zip(expt_ids, tau_rs, tau_as, x_ss, x_ps):\n",
    "            # compute surrogate neural response\n",
    "            i_s = np.array(df_tr['S']).astype(float)\n",
    "            i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "\n",
    "            r = smlt(i_s, i_p, tau_r, tau_a, x_s, x_p)\n",
    "\n",
    "            df_tr_nrl_dyn[f'R_{expt_id}'] = r\n",
    "\n",
    "        np.save(os.path.join(SAVE_DIR_DYN, f'{SAVE_PFX_DYN}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl_dyn}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-graham",
   "metadata": {},
   "source": [
    "# Dynamical model with halved response timescalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_DYN = 'data/simple/mlv_c/perturbed_ppln/c_baker_dyn_taurhalf'\n",
    "SAVE_PFX_DYN = 'mlv_c_baker_dyn_taurhalf'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_DYN):\n",
    "    os.makedirs(SAVE_DIR_DYN)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "df_dyn_param['TAU_R'] = df_dyn_param['TAU_R']/2\n",
    "df_dyn_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_dyn_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_dyn_param['TAU_R'])\n",
    "tau_as = np.array(df_dyn_param['TAU_A'])\n",
    "x_ss = np.array(df_dyn_param['X_S'])\n",
    "x_ps = np.array(df_dyn_param['X_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_dyn = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    # loop over neurons\n",
    "    for expt_id, tau_r, tau_a, x_s, x_p in zip(expt_ids, tau_rs, tau_as, x_ss, x_ps):\n",
    "        # compute surrogate neural response\n",
    "        i_s = np.array(df_tr['S']).astype(float)\n",
    "        i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "        \n",
    "        r = smlt(i_s, i_p, tau_r, tau_a, x_s, x_p)\n",
    "        \n",
    "        df_tr_nrl_dyn[f'R_{expt_id}'] = r\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_DYN, f'{SAVE_PFX_DYN}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl_dyn}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-opportunity",
   "metadata": {},
   "source": [
    "# Dynamical model with doubled response timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_DYN = 'data/simple/mlv_c/perturbed_ppln/c_baker_dyn_taurdbl'\n",
    "SAVE_PFX_DYN = 'mlv_c_baker_dyn_taurdbl'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_DYN):\n",
    "    os.makedirs(SAVE_DIR_DYN)\n",
    "\n",
    "# neural response fits from Baker data\n",
    "df_dyn_param = pd.read_csv('data/simple/neur/baker_dyn_fit_param.csv')\n",
    "df_dyn_param['TAU_R'] = df_dyn_param['TAU_R']*2\n",
    "df_dyn_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_dyn_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_dyn_param['TAU_R'])\n",
    "tau_as = np.array(df_dyn_param['TAU_A'])\n",
    "x_ss = np.array(df_dyn_param['X_S'])\n",
    "x_ps = np.array(df_dyn_param['X_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_dyn = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    # loop over neurons\n",
    "    for expt_id, tau_r, tau_a, x_s, x_p in zip(expt_ids, tau_rs, tau_as, x_ss, x_ps):\n",
    "        # compute surrogate neural response\n",
    "        i_s = np.array(df_tr['S']).astype(float)\n",
    "        i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "        \n",
    "        r = smlt(i_s, i_p, tau_r, tau_a, x_s, x_p)\n",
    "        \n",
    "        df_tr_nrl_dyn[f'R_{expt_id}'] = r\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_DYN, f'{SAVE_PFX_DYN}_tr_{ctr}.npy'), np.array([{'df': df_tr_nrl_dyn}]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
