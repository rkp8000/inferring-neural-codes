{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import signal, stats\n",
    "from sklearn import linear_model\n",
    "import sys\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from aux import get_seg\n",
    "from disp import set_font_size\n",
    "from my_stats import nanpearsonr\n",
    "\n",
    "from record import smlt_ppln_ma, smlt_ppln_lin, smlt_ppln_lin2e, smlt_ppln_ln, smlt_ppln_ln2e, smlt_ppln_masoff, smlt_ppln_masrb\n",
    "\n",
    "cc = np.concatenate\n",
    "\n",
    "FPS_DN = 8.5  # sampling rate from neural data\n",
    "DT_DN = 1/FPS_DN\n",
    "NT_H_DN = 85\n",
    "T_H_DN = np.arange(NT_H_DN)*DT_DN\n",
    "\n",
    "FPS = 30.03  # sampling rate of behavioral data\n",
    "DT = 1/FPS\n",
    "NT_H = int(round(NT_H_DN*FPS/FPS_DN))\n",
    "T_H = np.arange(NT_H)*DT\n",
    "\n",
    "H_S_COLS = [f'IT_H_S_{it}' for it in range(NT_H_DN)]\n",
    "H_P_COLS = [f'IT_H_P_{it}' for it in range(NT_H_DN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-taiwan",
   "metadata": {},
   "source": [
    "Load either Coen or WT Gold behavior data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_behav = pd.read_csv('data/simple/c_song_f_behav.csv')\n",
    "CTR_OFFSET = 0\n",
    "\n",
    "# df_behav = pd.read_csv('data/simple/w_song_f_behav.csv')\n",
    "# CTR_OFFSET = 276\n",
    "\n",
    "df_behav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split big df into dfs for individual trials\n",
    "ntr = np.max(df_behav.ID) + 1\n",
    "dfs_tr = [df_behav[df_behav.ID == i] for i in range(ntr)]\n",
    "\n",
    "tr_lens = np.array([len(df_tr) for df_tr in dfs_tr])\n",
    "tr_lens_cum = cc([[0], np.cumsum(tr_lens)])\n",
    "\n",
    "n_t_total = np.sum(tr_lens)\n",
    "assert n_t_total == tr_lens_cum[-1]\n",
    "df_behav = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-blocking",
   "metadata": {},
   "source": [
    "# MA\n",
    "Multiplicative-adaptation dynamical system neural responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_MA = 'data/simple/mlv/neur_basic/baker_ma'\n",
    "PFX_MA = 'mlv_baker_ma'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_MA):\n",
    "    os.makedirs(SAVE_DIR_MA)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_ma_param = pd.read_csv('data/simple/neur/baker_ma_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_ma_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_ma_param['TAU_R'])\n",
    "tau_as = np.array(df_ma_param['TAU_A'])\n",
    "x_ss = np.array(df_ma_param['X_S'])\n",
    "x_ps = np.array(df_ma_param['X_P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_ma = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    # simulate population response\n",
    "    rs = smlt_ppln_ma(i_s, i_p, tau_rs, tau_as, x_ss, x_ps, DT)\n",
    "        \n",
    "    df_tr_nrl_ma[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_MA, f'{PFX_MA}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_ma}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-gender",
   "metadata": {},
   "source": [
    "# LIN\n",
    "Linear neural responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_LIN = 'data/simple/mlv/neur_basic/baker_lin'\n",
    "PFX_LIN = 'mlv_baker_lin'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_LIN):\n",
    "    os.makedirs(SAVE_DIR_LIN)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_lin_param = pd.read_csv('data/simple/neur/baker_lin_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_lin_param['EXPT_ID']\n",
    "\n",
    "# extract filters (downsampled)\n",
    "hs_dn_s = np.array([df_lin_param[expt_ids == expt_id].iloc[0][H_S_COLS] for expt_id in expt_ids]).astype(float)\n",
    "hs_dn_p = np.array([df_lin_param[expt_ids == expt_id].iloc[0][H_P_COLS] for expt_id in expt_ids]).astype(float)\n",
    "\n",
    "# upsample filters via interpolation\n",
    "hs_s = np.array([np.interp(T_H, T_H_DN, cc([[0], h_dn_s])[:-1]) for h_dn_s in hs_dn_s])\n",
    "hs_p = np.array([np.interp(T_H, T_H_DN, cc([[0], h_dn_p])[:-1]) for h_dn_p in hs_dn_p])\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 5), tight_layout=True)\n",
    "for cexpt, ax_col in zip([0, 10, 30, 50], axs.T):\n",
    "    ax_col[0].plot(T_H_DN, hs_dn_s[cexpt], c='b', lw=2)\n",
    "    ax_col[0].plot(T_H, hs_s[cexpt], c='k', lw=1)\n",
    "    ax_col[0].set_title(f'EXPT_ID {expt_ids[cexpt]}: Sine')\n",
    "    \n",
    "    ax_col[1].plot(T_H_DN, hs_dn_p[cexpt], c='r', lw=2)\n",
    "    ax_col[1].plot(T_H, hs_p[cexpt], c='k', lw=1)\n",
    "    ax_col[1].set_title(f'EXPT_ID {expt_ids[cexpt]}: Pulse')\n",
    "    \n",
    "set_font_size(axs, 12)\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 5), tight_layout=True)\n",
    "for cexpt, ax_col in zip([0, 10, 30, 50], axs.T):\n",
    "    ax_col[0].plot(T_H_DN, hs_dn_s[cexpt].cumsum()*DT_DN, c='b', lw=2)\n",
    "    ax_col[0].plot(T_H, hs_s[cexpt].cumsum()*DT, c='k', lw=1)\n",
    "    ax_col[0].set_title(f'EXPT_ID {expt_ids[cexpt]}: Sine (step/cum)')\n",
    "    \n",
    "    ax_col[1].plot(T_H_DN, hs_dn_p[cexpt].cumsum()*DT_DN, c='r', lw=2)\n",
    "    ax_col[1].plot(T_H, hs_p[cexpt].cumsum()*DT, c='k', lw=1)\n",
    "    ax_col[1].set_title(f'EXPT_ID {expt_ids[cexpt]}: Pulse (step/cum)')\n",
    "    \n",
    "set_font_size(axs, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-anatomy",
   "metadata": {},
   "source": [
    "Neural responses are given by convolution of each neuron's impulse response with song\n",
    "\n",
    "$$r(t) = h_{sine}(t) \\circledast I_{sine}(t) + h_{pulse}(t) \\circledast I_{pulse}(t) = \\int_0^{\\infty} h_{sine}(t') I_{sine}(t-t')dt' + \\int_0^{\\infty} h_{pulse}(t') I_{pulse}(t-t')dt'$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_lin = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    rs = smlt_ppln_lin(i_s, i_p, hs_s.T, hs_p.T, DT)\n",
    "        \n",
    "    df_tr_nrl_lin[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "    \n",
    "    np.save(os.path.join(SAVE_DIR_LIN, f'{PFX_LIN}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_lin}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-allocation",
   "metadata": {},
   "source": [
    "# LIN-2E\n",
    "Two-exponential linear neural responses. Each filter is sum of two exponentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_LIN2E = 'data/simple/mlv/neur_basic/baker_lin2e'\n",
    "PFX_LIN2E = 'mlv_baker_lin2e'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_LIN2E):\n",
    "    os.makedirs(SAVE_DIR_LIN2E)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_lin2e_param = pd.read_csv('data/simple/neur/baker_lin2e_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_lin2e_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "x_s_0s = np.array(df_lin2e_param['X_S_0'])\n",
    "tau_s_0s = np.array(df_lin2e_param['TAU_S_0'])\n",
    "x_s_1s = np.array(df_lin2e_param['X_S_1'])\n",
    "tau_s_1s = np.array(df_lin2e_param['TAU_S_1'])\n",
    "x_p_0s = np.array(df_lin2e_param['X_P_0'])\n",
    "tau_p_0s = np.array(df_lin2e_param['TAU_P_0'])\n",
    "x_p_1s = np.array(df_lin2e_param['X_P_1'])\n",
    "tau_p_1s = np.array(df_lin2e_param['TAU_P_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_lin2e = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "         \n",
    "    rs = smlt_ppln_lin2e(i_s, i_p, T_H, x_s_0s, tau_s_0s, x_s_1s, tau_s_1s, x_p_0s, tau_p_0s, x_p_1s, tau_p_1s, DT)\n",
    "    \n",
    "    df_tr_nrl_lin2e[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "    \n",
    "    np.save(os.path.join(SAVE_DIR_LIN2E, f'{PFX_LIN2E}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_lin2e}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-vampire",
   "metadata": {},
   "source": [
    "# LIN-R\n",
    "Linear neural responses (fit with ridge regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_LINR = 'data/simple/mlv/neur_basic/baker_linr'\n",
    "PFX_LINR = 'mlv_baker_linr'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_LINR):\n",
    "    os.makedirs(SAVE_DIR_LINR)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_linr_param = pd.read_csv('data/simple/neur/baker_linr_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_linr_param['EXPT_ID']\n",
    "\n",
    "# extract filters (downsampled)\n",
    "hs_dn_s = np.array([df_linr_param[expt_ids == expt_id].iloc[0][H_S_COLS] for expt_id in expt_ids]).astype(float)\n",
    "hs_dn_p = np.array([df_linr_param[expt_ids == expt_id].iloc[0][H_P_COLS] for expt_id in expt_ids]).astype(float)\n",
    "\n",
    "# upsample filters via interpolation\n",
    "hs_s = np.array([np.interp(T_H, T_H_DN, cc([[0], h_dn_s])[:-1]) for h_dn_s in hs_dn_s])\n",
    "hs_p = np.array([np.interp(T_H, T_H_DN, cc([[0], h_dn_p])[:-1]) for h_dn_p in hs_dn_p])\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 5), tight_layout=True)\n",
    "for cexpt, ax_col in zip([0, 10, 30, 50], axs.T):\n",
    "    ax_col[0].plot(T_H_DN, hs_dn_s[cexpt], c='b', lw=2)\n",
    "    ax_col[0].plot(T_H, hs_s[cexpt], c='k', lw=1)\n",
    "    ax_col[0].set_title(f'EXPT_ID {expt_ids[cexpt]}: Sine')\n",
    "    \n",
    "    ax_col[1].plot(T_H_DN, hs_dn_p[cexpt], c='r', lw=2)\n",
    "    ax_col[1].plot(T_H, hs_p[cexpt], c='k', lw=1)\n",
    "    ax_col[1].set_title(f'EXPT_ID {expt_ids[cexpt]}: Pulse')\n",
    "    \n",
    "set_font_size(axs, 12)\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 5), tight_layout=True)\n",
    "for cexpt, ax_col in zip([0, 10, 30, 50], axs.T):\n",
    "    ax_col[0].plot(T_H_DN, hs_dn_s[cexpt].cumsum()*DT_DN, c='b', lw=2)\n",
    "    ax_col[0].plot(T_H, hs_s[cexpt].cumsum()*DT, c='k', lw=1)\n",
    "    ax_col[0].set_title(f'EXPT_ID {expt_ids[cexpt]}: Sine (step/cum)')\n",
    "    \n",
    "    ax_col[1].plot(T_H_DN, hs_dn_p[cexpt].cumsum()*DT_DN, c='r', lw=2)\n",
    "    ax_col[1].plot(T_H, hs_p[cexpt].cumsum()*DT, c='k', lw=1)\n",
    "    ax_col[1].set_title(f'EXPT_ID {expt_ids[cexpt]}: Pulse (step/cum)')\n",
    "    \n",
    "set_font_size(axs, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate linear neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_linr = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    rs = smlt_ppln_lin(i_s, i_p, hs_s.T, hs_p.T, DT)\n",
    "        \n",
    "    df_tr_nrl_linr[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "    \n",
    "    np.save(os.path.join(SAVE_DIR_LINR, f'{PFX_LINR}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_linr}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-milton",
   "metadata": {},
   "source": [
    "# LN\n",
    "Linear-nonlinear neural responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_LN = 'data/simple/mlv/neur_basic/baker_ln'\n",
    "PFX_LN = 'mlv_baker_ln'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_LN):\n",
    "    os.makedirs(SAVE_DIR_LN)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_ln_param = pd.read_csv('data/simple/neur/baker_ln_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_ln_param['EXPT_ID']\n",
    "\n",
    "r_mins = np.array([df_ln_param[expt_ids == expt_id].iloc[0]['R_MIN'] for expt_id in expt_ids])\n",
    "r_maxs = np.array([df_ln_param[expt_ids == expt_id].iloc[0]['R_MAX'] for expt_id in expt_ids])\n",
    "z_0s = np.array([df_ln_param[expt_ids == expt_id].iloc[0]['Z_0'] for expt_id in expt_ids])\n",
    "betas = np.array([df_ln_param[expt_ids == expt_id].iloc[0]['BETA'] for expt_id in expt_ids])\n",
    "\n",
    "# extract filters (downsampled)\n",
    "hs_dn_s = np.array([df_ln_param[expt_ids == expt_id].iloc[0][H_S_COLS] for expt_id in expt_ids]).astype(float)\n",
    "hs_dn_p = np.array([df_ln_param[expt_ids == expt_id].iloc[0][H_P_COLS] for expt_id in expt_ids]).astype(float)\n",
    "\n",
    "# # upsample filters via interpolation\n",
    "hs_s = np.array([np.interp(T_H, T_H_DN, cc([[0], h_dn_s])[:-1]) for h_dn_s in hs_dn_s])\n",
    "hs_p = np.array([np.interp(T_H, T_H_DN, cc([[0], h_dn_p])[:-1]) for h_dn_p in hs_dn_p])\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 5), tight_layout=True)\n",
    "for cexpt, ax_col in zip([0, 10, 30, 50], axs.T):\n",
    "    ax_col[0].plot(T_H_DN, hs_dn_s[cexpt], c='b', lw=2)\n",
    "    ax_col[0].plot(T_H, hs_s[cexpt], c='k', lw=1)\n",
    "    ax_col[0].set_title(f'EXPT_ID {expt_ids[cexpt]}: Sine')\n",
    "    \n",
    "    ax_col[1].plot(T_H_DN, hs_dn_p[cexpt], c='r', lw=2)\n",
    "    ax_col[1].plot(T_H, hs_p[cexpt], c='k', lw=1)\n",
    "    ax_col[1].set_title(f'EXPT_ID {expt_ids[cexpt]}: Pulse')\n",
    "    \n",
    "set_font_size(axs, 12)\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 5), tight_layout=True)\n",
    "for cexpt, ax_col in zip([0, 10, 30, 50], axs.T):\n",
    "    ax_col[0].plot(T_H_DN, hs_dn_s[cexpt].cumsum()*DT_DN, c='b', lw=2)\n",
    "    ax_col[0].plot(T_H, hs_s[cexpt].cumsum()*DT, c='k', lw=1)\n",
    "    ax_col[0].set_title(f'EXPT_ID {expt_ids[cexpt]}: Sine (step/cum)')\n",
    "    \n",
    "    ax_col[1].plot(T_H_DN, hs_dn_p[cexpt].cumsum()*DT_DN, c='r', lw=2)\n",
    "    ax_col[1].plot(T_H, hs_p[cexpt].cumsum()*DT, c='k', lw=1)\n",
    "    ax_col[1].set_title(f'EXPT_ID {expt_ids[cexpt]}: Pulse (step/cum)')\n",
    "    \n",
    "set_font_size(axs, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-oracle",
   "metadata": {},
   "source": [
    "Neural responses are given by convolution of each neuron's impulse response with song, followed by sigmoid nonlin\n",
    "\n",
    "$$z(t) = h_{sine}(t) \\circledast I_{sine}(t) + h_{pulse}(t) \\circledast I_{pulse}(t)$$\n",
    "\n",
    "$$r(t) = r_{min} + (r_{max} - r_{min})\\left[\\frac{\\tanh(\\beta(z - z_0)) - 1}{2}\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_ln = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    rs = smlt_ppln_ln(i_s, i_p, hs_s.T, hs_p.T, r_mins, r_maxs, z_0s, betas, DT)\n",
    "    df_tr_nrl_ln[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_LN, f'{PFX_LN}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_ln}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-affiliate",
   "metadata": {},
   "source": [
    "# LN-2E\n",
    "Two-exponential linear-nonlinear neural responses. Each filter is sum of two exponentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_LN2E = 'data/simple/mlv/neur_basic/baker_ln2e'\n",
    "PFX_LN2E = 'mlv_baker_ln2e'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_LN2E):\n",
    "    os.makedirs(SAVE_DIR_LN2E)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_ln2e_param = pd.read_csv('data/simple/neur/baker_ln2e_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_ln2e_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "x_s_0s = np.array(df_ln2e_param['X_S_0'])\n",
    "tau_s_0s = np.array(df_ln2e_param['TAU_S_0'])\n",
    "x_s_1s = np.array(df_ln2e_param['X_S_1'])\n",
    "tau_s_1s = np.array(df_ln2e_param['TAU_S_1'])\n",
    "x_p_0s = np.array(df_ln2e_param['X_P_0'])\n",
    "tau_p_0s = np.array(df_ln2e_param['TAU_P_0'])\n",
    "x_p_1s = np.array(df_ln2e_param['X_P_1'])\n",
    "tau_p_1s = np.array(df_ln2e_param['TAU_P_1'])\n",
    "r_mins = np.array(df_ln2e_param['R_MIN'])\n",
    "r_maxs = np.array(df_ln2e_param['R_MAX'])\n",
    "z_0s = np.array(df_ln2e_param['Z_0'])\n",
    "betas = np.array(df_ln2e_param['BETA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_ln2e = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    rs = smlt_ppln_ln2e(i_s, i_p, T_H, x_s_0s, tau_s_0s, x_s_1s, tau_s_1s, x_p_0s, tau_p_0s, x_p_1s, tau_p_1s, r_mins, r_maxs, z_0s, betas, DT)\n",
    "    df_tr_nrl_ln2e[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "    \n",
    "    np.save(os.path.join(SAVE_DIR_LN2E, f'{PFX_LN2E}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_ln2e}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-attribute",
   "metadata": {},
   "source": [
    "# LN-R\n",
    "Linear-nonlinear neural responses (fit with ridge regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_LNR = 'data/simple/mlv/neur_basic/baker_lnr'\n",
    "PFX_LNR = 'mlv_baker_lnr'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_LNR):\n",
    "    os.makedirs(SAVE_DIR_LNR)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_lnr_param = pd.read_csv('data/simple/neur/baker_lnr_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_lnr_param['EXPT_ID']\n",
    "\n",
    "r_mins = np.array([df_lnr_param[expt_ids == expt_id].iloc[0]['R_MIN'] for expt_id in expt_ids])\n",
    "r_maxs = np.array([df_lnr_param[expt_ids == expt_id].iloc[0]['R_MAX'] for expt_id in expt_ids])\n",
    "z_0s = np.array([df_lnr_param[expt_ids == expt_id].iloc[0]['Z_0'] for expt_id in expt_ids])\n",
    "betas = np.array([df_lnr_param[expt_ids == expt_id].iloc[0]['BETA'] for expt_id in expt_ids])\n",
    "\n",
    "# extract filters (downsampled)\n",
    "hs_dn_s = np.array([df_lnr_param[expt_ids == expt_id].iloc[0][H_S_COLS] for expt_id in expt_ids]).astype(float)\n",
    "hs_dn_p = np.array([df_lnr_param[expt_ids == expt_id].iloc[0][H_P_COLS] for expt_id in expt_ids]).astype(float)\n",
    "\n",
    "# # upsample filters via interpolation\n",
    "hs_s = np.array([np.interp(T_H, T_H_DN, cc([[0], h_dn_s])[:-1]) for h_dn_s in hs_dn_s])\n",
    "hs_p = np.array([np.interp(T_H, T_H_DN, cc([[0], h_dn_p])[:-1]) for h_dn_p in hs_dn_p])\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 5), tight_layout=True)\n",
    "for cexpt, ax_col in zip([0, 10, 30, 50], axs.T):\n",
    "    ax_col[0].plot(T_H_DN, hs_dn_s[cexpt], c='b', lw=2)\n",
    "    ax_col[0].plot(T_H, hs_s[cexpt], c='k', lw=1)\n",
    "    ax_col[0].set_title(f'EXPT_ID {expt_ids[cexpt]}: Sine')\n",
    "    \n",
    "    ax_col[1].plot(T_H_DN, hs_dn_p[cexpt], c='r', lw=2)\n",
    "    ax_col[1].plot(T_H, hs_p[cexpt], c='k', lw=1)\n",
    "    ax_col[1].set_title(f'EXPT_ID {expt_ids[cexpt]}: Pulse')\n",
    "    \n",
    "set_font_size(axs, 12)\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(12, 5), tight_layout=True)\n",
    "for cexpt, ax_col in zip([0, 10, 30, 50], axs.T):\n",
    "    ax_col[0].plot(T_H_DN, hs_dn_s[cexpt].cumsum()*DT_DN, c='b', lw=2)\n",
    "    ax_col[0].plot(T_H, hs_s[cexpt].cumsum()*DT, c='k', lw=1)\n",
    "    ax_col[0].set_title(f'EXPT_ID {expt_ids[cexpt]}: Sine (step/cum)')\n",
    "    \n",
    "    ax_col[1].plot(T_H_DN, hs_dn_p[cexpt].cumsum()*DT_DN, c='r', lw=2)\n",
    "    ax_col[1].plot(T_H, hs_p[cexpt].cumsum()*DT, c='k', lw=1)\n",
    "    ax_col[1].set_title(f'EXPT_ID {expt_ids[cexpt]}: Pulse (step/cum)')\n",
    "    \n",
    "set_font_size(axs, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_lnr = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    rs = smlt_ppln_ln(i_s, i_p, hs_s.T, hs_p.T, r_mins, r_maxs, z_0s, betas, DT)\n",
    "    df_tr_nrl_lnr[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "    \n",
    "    np.save(os.path.join(SAVE_DIR_LNR, f'{PFX_LNR}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_lnr}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-maine",
   "metadata": {},
   "source": [
    "# MA-S-OFF (Q, P)\n",
    "Multiplicative-adaptation neurons w/ responses to sine-offsets followed by quiet or pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_MASOFF = 'data/simple/mlv/neur_basic/baker_masoff'\n",
    "PFX_MASOFF = 'mlv_baker_masoff'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_MASOFF):\n",
    "    os.makedirs(SAVE_DIR_MASOFF)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_masoff_param = pd.read_csv('data/simple/neur/baker_masoff_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_masoff_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_masoff_param['TAU_R'])\n",
    "tau_as = np.array(df_masoff_param['TAU_A'])\n",
    "x_s_all = np.array(df_masoff_param['X_S'])\n",
    "x_p_all = np.array(df_masoff_param['X_P'])\n",
    "x_qs_all = np.array(df_masoff_param['X_QS'])\n",
    "x_ps_all = np.array(df_masoff_param['X_PS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_masoff = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    rs = smlt_ppln_masoff(i_s, i_p, tau_rs, tau_as, x_s_all, x_p_all, x_qs_all, x_ps_all, DT)\n",
    "    df_tr_nrl_masoff[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "    \n",
    "    np.save(os.path.join(SAVE_DIR_MASOFF, f'{PFX_MASOFF}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_masoff}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-blogger",
   "metadata": {},
   "source": [
    "# MA-S-OFF (Q)\n",
    "Multiplicative-adaptation neurons w/ response to sine-offsets followed by quiet only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_MAQS = 'data/simple/mlv/neur_basic/baker_maqs'\n",
    "PFX_MAQS = 'mlv_baker_maqs'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_MAQS):\n",
    "    os.makedirs(SAVE_DIR_MAQS)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_masoff_param = pd.read_csv('data/simple/neur/baker_masoff_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_masoff_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_masoff_param['TAU_R'])\n",
    "tau_as = np.array(df_masoff_param['TAU_A'])\n",
    "x_s_all = np.array(df_masoff_param['X_S'])\n",
    "x_p_all = np.array(df_masoff_param['X_P'])\n",
    "x_qs_all = np.array(df_masoff_param['X_QS'])\n",
    "x_ps_all = np.array(df_masoff_param['X_PS'])*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_maqs = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "     \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    rs = smlt_ppln_masoff(i_s, i_p, tau_rs, tau_as, x_s_all, x_p_all, x_qs_all, x_ps_all, DT)\n",
    "    df_tr_nrl_maqs[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "    \n",
    "    np.save(os.path.join(SAVE_DIR_MAQS, f'{PFX_MAQS}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_maqs}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-atlas",
   "metadata": {},
   "source": [
    "# MA-S-RB (Q, P)\n",
    "Multiplicative-adaptation neurons w/ \"rebound\" responses to sine-offset followed by quiet or pulse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-glance",
   "metadata": {},
   "source": [
    "$$\\tau_r \\frac{dr}{dt} = -r + (1-a_s)x_sI_s(t) + (1-a_p)x_pI_p(t) + a_sx_{q/s}I_{q/s} + a_sx_{p/s}I_{p/s}$$\n",
    "\n",
    "$$\\tau_a \\frac{da_s}{dt} = -a_s + I_s(t) \\quad\\quad\\quad \\tau_a \\frac{da_p}{dt} = -a_p + I_p(t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_MAQPSRB = 'data/simple/mlv/neur_basic/baker_maqpsrb'\n",
    "PFX_MAQPSRB = 'mlv_baker_maqpsrb'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_MAQPSRB):\n",
    "    os.makedirs(SAVE_DIR_MAQPSRB)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_masoff_param = pd.read_csv('data/simple/neur/baker_masoff_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_masoff_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_masoff_param['TAU_R'])\n",
    "tau_as = np.array(df_masoff_param['TAU_A'])\n",
    "x_s_all = np.array(df_masoff_param['X_S'])\n",
    "x_p_all = np.array(df_masoff_param['X_P'])\n",
    "x_qs_all = np.array(df_masoff_param['X_QS'])\n",
    "x_ps_all = np.array(df_masoff_param['X_PS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_maqpsrb = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    rs = smlt_ppln_masrb(i_s, i_p, tau_rs, tau_as, x_s_all, x_p_all, x_qs_all, x_ps_all, DT)\n",
    "    df_tr_nrl_maqpsrb[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "        \n",
    "    np.save(os.path.join(SAVE_DIR_MAQPSRB, f'{PFX_MAQPSRB}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_maqpsrb}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-faith",
   "metadata": {},
   "source": [
    "# MA-S-RB (Q)\n",
    "Multiplicative-adaptation neurons w/ \"rebound\" responses to sine-offset followed by quiet only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-adoption",
   "metadata": {},
   "source": [
    "$$\\tau_r \\frac{dr}{dt} = -r + (1-a_s)x_sI_s(t) + (1-a_p)x_pI_p(t) + a_sx_{q/s}I_{q/s}$$\n",
    "\n",
    "$$\\tau_a \\frac{da_s}{dt} = -a_s + I_s(t) \\quad\\quad\\quad \\tau_a \\frac{da_p}{dt} = -a_p + I_p(t)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR_MAQSRB = 'data/simple/mlv/neur_basic/baker_maqsrb'\n",
    "PFX_MAQSRB = 'mlv_baker_maqsrb'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR_MAQSRB):\n",
    "    os.makedirs(SAVE_DIR_MAQSRB)\n",
    "    \n",
    "# neural response fits from Baker data\n",
    "df_masoff_param = pd.read_csv('data/simple/neur/baker_masoff_fit_param.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_ids = df_masoff_param['EXPT_ID']\n",
    "\n",
    "# get parameters\n",
    "tau_rs = np.array(df_masoff_param['TAU_R'])\n",
    "tau_as = np.array(df_masoff_param['TAU_A'])\n",
    "x_s_all = np.array(df_masoff_param['X_S'])\n",
    "x_p_all = np.array(df_masoff_param['X_P'])\n",
    "x_qs_all = np.array(df_masoff_param['X_QS'])\n",
    "x_ps_all = np.array(df_masoff_param['X_PS'])*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute surrogate neural responses for each trial\n",
    "for ctr, df_tr in enumerate(dfs_tr):\n",
    "    df_tr_nrl_maqsrb = df_tr.copy()\n",
    "    sys.stdout.write('.')\n",
    "    \n",
    "    i_s = np.array(df_tr['S']).astype(float)\n",
    "    i_p = np.array(df_tr['P'] | df_tr['F']).astype(float)\n",
    "    \n",
    "    rs = smlt_ppln_masrb(i_s, i_p, tau_rs, tau_as, x_s_all, x_p_all, x_qs_all, x_ps_all, DT)\n",
    "    df_tr_nrl_maqsrb[[f'R_{expt_id}' for expt_id in expt_ids]] = rs\n",
    "    \n",
    "    np.save(os.path.join(SAVE_DIR_MAQSRB, f'{PFX_MAQSRB}_tr_{ctr+CTR_OFFSET}.npy'), np.array([{'df': df_tr_nrl_maqsrb}]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
